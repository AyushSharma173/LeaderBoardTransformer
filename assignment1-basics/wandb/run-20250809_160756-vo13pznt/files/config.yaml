_wandb:
    value:
        cli_version: 0.19.9
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 2
                - 14
                - 15
                - 17
                - 23
                - 55
                - 62
            "4": 3.12.3
            "5": 0.19.9
            "8":
                - 5
            "12": 0.19.9
            "13": linux-x86_64
batch_size:
    value: 16
context_length:
    value: 128
d_ff:
    value: 1024
d_model:
    value: 256
data/train_tokens:
    value: 539833513
data/val_tokens:
    value: 5452049
eval_every:
    value: 50
lr:
    value: 0.0019235933732672016
max_steps:
    value: 500
model/context_length:
    value: 128
model/d_ff:
    value: 1024
model/d_model:
    value: 256
model/max_seq_len:
    value: 128
model/num_heads:
    value: 8
model/num_layers:
    value: 4
model/params_M:
    value: 20.580608
model/theta:
    value: 10000
model/total_params:
    value: 20580608
model/trainable_params:
    value: 20580608
model/vocab_size:
    value: 32000
num_heads:
    value: 8
num_layers:
    value: 4
training/alpha_max:
    value: 0.0003
training/alpha_min:
    value: 1e-05
training/batch_size:
    value: 16
training/clip_grad:
    value: 1
training/eval_every:
    value: 50
training/lr:
    value: 0.0019235933732672016
training/max_steps:
    value: 500
training/t_c:
    value: 100000
training/t_w:
    value: 2000
